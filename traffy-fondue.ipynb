{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import findspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, explode, regexp_replace, split, col, size, array_contains, isnan, when, count, array, reverse, udf, unix_timestamp, from_unixtime, date_format, format_number, length\n",
    "from pyspark.sql.types import ArrayType, StringType, DoubleType\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler, IndexToString\n",
    "from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier, RandomForestClassifier\n",
    "from pyspark.ml.regression import GeneralizedLinearRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.stats import kurtosis, skew\n",
    "import math\n",
    "import folium\n",
    "from geopy.geocoders import Nominatim\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_url = 'local'\n",
    "spark = SparkSession.builder\\\n",
    "        .master(spark_url)\\\n",
    "        .appName('Spark Project')\\\n",
    "        .config(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\\\n",
    "        .getOrCreate()\n",
    "spark.conf.set(\"spark.sql.csv.parser.multiLine\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------+--------------------+--------------------+--------------------+--------------------+------------------+--------------------+-----------+--------+--------------------+--------------------+--------------+----+------------+--------------------+\n",
      "|  ticket_id|               type|        organization|             comment|               photo|         photo_after|            coords|             address|subdistrict|district|            province|           timestamp|         state|star|count_reopen|       last_activity|\n",
      "+-----------+-------------------+--------------------+--------------------+--------------------+--------------------+------------------+--------------------+-----------+--------+--------------------+--------------------+--------------+----+------------+--------------------+\n",
      "|2021-9LHDM6|                 {}|                null|            ไม่มีภาพ|https://storage.g...|                null|100.48661,13.79386|1867 จรัญสนิทวงศ์...|    บางพลัด| บางพลัด|       กรุงเทพมหานคร|2021-09-01 10:44:...|กำลังดำเนินการ|null|        null|2022-02-22 04:59:...|\n",
      "|2021-FYJTFP|        {ความสะอาด}|          เขตบางซื่อ|             ขยะเยอะ|https://storage.g...|                null|100.53084,13.81865|12/14 ถนน กรุงเทพ...|       null|    null|       กรุงเทพมหานคร|2021-09-03 12:51:...|     เสร็จสิ้น|null|        null|2022-06-04 15:34:...|\n",
      "|2021-8GKAR9|            {สายไฟ}|ยังไม่มีหน่วยงานร...|1. เถาวัลย์งอดบนส...|https://storage.g...|                null|100.57685,13.79704|335/31 ลาดพร้าว แ...|  สามเสนนอก|ห้วยขวาง|จังหวัดกรุงเทพมหานคร|2021-09-19 06:47:...|กำลังดำเนินการ|null|        null|2022-02-22 04:30:...|\n",
      "|2021-AFPUXZ|        {ถนน,สะพาน}|                null|1 ซ่อมทางเท้าหลัง...|https://storage.g...|                null|100.52916,13.72338|37 10 ซอย สีลม 9 ...|       สีลม|  บางรัก|       กรุงเทพมหานคร|2021-09-19 07:40:...|กำลังดำเนินการ|null|        null|2022-02-22 04:30:...|\n",
      "|2021-CGPMUN|{น้ำท่วม,ร้องเรียน}|เขตประเวศ,ฝ่ายโยธ...|น้ำท่วมเวลาฝนตกแล...|https://storage.g...|https://storage.g...|100.66709,13.67891|189 เฉลิมพระเกียร...|    หนองบอน|  ประเวศ|       กรุงเทพมหานคร|2021-09-19 14:56:...|     เสร็จสิ้น|   4|        null|2022-06-21 08:21:...|\n",
      "+-----------+-------------------+--------------------+--------------------+--------------------+--------------------+------------------+--------------------+-----------+--------+--------------------+--------------------+--------------+----+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = 'bangkok_traffy.csv'\n",
    "df = spark.read.option(\"multiLine\", \"true\").csv(path, header=True, inferSchema=True)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+------------+-------+-----+-----------+------+-------+-----------+--------+--------+---------+-----+------+------------+-------------+\n",
      "|ticket_id|type|organization|comment|photo|photo_after|coords|address|subdistrict|district|province|timestamp|state|  star|count_reopen|last_activity|\n",
      "+---------+----+------------+-------+-----+-----------+------+-------+-----------+--------+--------+---------+-----+------+------------+-------------+\n",
      "|     2413|1550|        2640|   3911| 2089|      85624|  2019|   4433|       2089|    2092|    2393|     2233| 2026|164087|      120042|         2558|\n",
      "+---------+----+------------+-------+-----+-----------+------+-------+-----------+--------+--------+---------+-----+------+------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "null_counts = df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns])\n",
    "null_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(ticket_id=None, type='{ถนน}', organization='สำนักงาน ป.ป.ท.,เขตจอมทอง,ฝ่ายเทศกิจ เขตจอมทอง,ผอ.เขตจอมทอง (นายณัฐพงษ์),กลุ่มกรุงธนเหนือ (รองปลัดฯ เฉลิมพล)', comment=None, photo='https://storage.googleapis.com/traffy_public_bucket/TeamChadChart/corruption_photo2.png', photo_after='https://storage.googleapis.com/traffy_public_bucket/attachment/2022-06/e9596093de70ae8abacd6574f26a2d0f4466fe9f.jpg', coords='100.45568,13.69103', address=None, subdistrict='บางขุนเทียน', district='จอมทอง', province='กรุงเทพมหานคร', timestamp='2022-06-09 23:34:34.98044+00', state='เสร็จสิ้น', star='5', count_reopen=None, last_activity='2022-06-10 11:02:34.607728+00') \n",
      "\n",
      "Row(ticket_id='2022-7DABXT', type='{สะพาน}', organization=None, comment='\"เคยดีใจมีสายสีน้ำเงินสถานี\"\"แยกไฟฉาย\"\"', photo=None, photo_after=None, coords=None, address=None, subdistrict=None, district=None, province=None, timestamp=None, state=None, star=None, count_reopen=None, last_activity=None) \n",
      "\n",
      "Row(ticket_id='2022-7DABXT', type='{สะพาน}', organization=None, comment='\"เคยดีใจมีสายสีน้ำเงินสถานี\"\"แยกไฟฉาย\"\"', photo=None, photo_after=None, coords=None, address=None, subdistrict=None, district=None, province=None, timestamp=None, state=None, star=None, count_reopen=None, last_activity=None) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter the DataFrame to include only rows with null values in the \"column_name\" column\n",
    "def check_first_null(filtered_df):\n",
    "    # Check if the filtered DataFrame is empty\n",
    "    if filtered_df.count() == 0:\n",
    "        return f\"No null values in {filtered_df}.\"\n",
    "    else:\n",
    "        first_row = filtered_df.head()\n",
    "        return first_row\n",
    "    \n",
    "ticket_id_null_df = df.filter(df.ticket_id.isNull())\n",
    "coords_null_df = df.filter(df.coords.isNull())\n",
    "address_null_df = df.filter(df.address.isNull())\n",
    "print(check_first_null(ticket_id_null_df), \"\\n\")\n",
    "print(check_first_null(coords_null_df), \"\\n\")\n",
    "print(check_first_null(address_null_df), \"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above cells give us the first row with null value from each column selected (ticket_id, coords, address) to tell some relationship of those null value.\n",
    "1. The ticket_id is null when the state='เสร็จสิ้น', it's mean we can drop this column significantly.\n",
    "2. The address has null value 2 times more than coords. In the first null row we can see both of them are null. So it might tell that if no coords, no address too and not vice versa. We'll check in next step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "|coords|address|\n",
      "+------+-------+\n",
      "|     1|   2415|\n",
      "+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sub = ['coords', 'address']\n",
    "df = df.dropna(how='all', subset=sub)\n",
    "sub_null_counts = df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in sub])\n",
    "sub_null_counts.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the null coords most dissapear. So, we don't need to map any address to coords and we can also drop all remained null column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(how='all', subset=['coords'])\n",
    "df = df.dropna(how='all', subset=['address'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this step, we'll use df_use to be a data for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------+--------+--------------------+-------------------+-----+----+------------+-------------------+---------+\n",
      "|  ticket_id|                type|        organization|             comment|               photo|         photo_after|              coords|             address|subdistrict|district|            province|          timestamp|state|star|count_reopen|      last_activity|time_diff|\n",
      "+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------+--------+--------------------+-------------------+-----+----+------------+-------------------+---------+\n",
      "|2021-9LHDM6|                  []|                null|            ไม่มีภาพ|https://storage.g...|                null|[13.79386, 100.48...|1867 จรัญสนิทวงศ์...|    บางพลัด| บางพลัด|       กรุงเทพมหานคร|2021-09-01 10:44:00|    0|null|        null|2022-02-22 04:59:00|      174|\n",
      "|2021-FYJTFP|         [ความสะอาด]|          เขตบางซื่อ|             ขยะเยอะ|https://storage.g...|                null|[13.81865, 100.53...|12/14 ถนน กรุงเทพ...|       null|    null|       กรุงเทพมหานคร|2021-09-03 12:51:00|    1|null|        null|2022-06-04 15:34:00|      274|\n",
      "|2021-8GKAR9|             [สายไฟ]|ยังไม่มีหน่วยงานร...|1. เถาวัลย์งอดบนส...|https://storage.g...|                null|[13.79704, 100.57...|335/31 ลาดพร้าว แ...|  สามเสนนอก|ห้วยขวาง|จังหวัดกรุงเทพมหานคร|2021-09-19 06:47:00|    0|null|        null|2022-02-22 04:30:00|      156|\n",
      "|2021-AFPUXZ|        [ถนน, สะพาน]|                null|1 ซ่อมทางเท้าหลัง...|https://storage.g...|                null|[13.72338, 100.52...|37 10 ซอย สีลม 9 ...|       สีลม|  บางรัก|       กรุงเทพมหานคร|2021-09-19 07:40:00|    0|null|        null|2022-02-22 04:30:00|      156|\n",
      "|2021-CGPMUN|[น้ำท่วม, ร้องเรียน]|เขตประเวศ,ฝ่ายโยธ...|น้ำท่วมเวลาฝนตกแล...|https://storage.g...|https://storage.g...|[13.67891, 100.66...|189 เฉลิมพระเกียร...|    หนองบอน|  ประเวศ|       กรุงเทพมหานคร|2021-09-19 14:56:00|    1|   4|        null|2022-06-21 08:21:00|      275|\n",
      "+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+-----------+--------+--------------------+-------------------+-----+----+------------+-------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# change state to boolean \n",
    "df_use = df.withColumn('state', when(df.state == 'เสร็จสิ้น', 1).otherwise(0))\n",
    "\n",
    "# change type to list\n",
    "df_use = df_use.withColumn(\"type\", split(regexp_replace(\"type\", \"[{}]\", \"\"), \",\"))\n",
    "df_use = df_use.dropna(how='all', subset=['type'])\n",
    "\n",
    "# change coords to pair and swap them into format [latitude, longtitude]\n",
    "flatten = udf(lambda x: list(chain.from_iterable(x)), ArrayType(StringType()))\n",
    "df_use = df_use.withColumn('coords', array(reverse(split(df.coords, ','))))\n",
    "df_use = df_use.withColumn('coords', flatten('coords'))\n",
    "\n",
    "# change timestamp and last_activity\n",
    "df_use = df_use.withColumn('timestamp', from_unixtime(unix_timestamp(col('timestamp'), 'yyyy-MM-dd HH:mm')))\n",
    "df_use = df_use.withColumn('last_activity', from_unixtime(unix_timestamp(col('last_activity'), 'yyyy-MM-dd HH:mm')))\n",
    "df_use = df_use.withColumn('time_diff', (unix_timestamp(col('last_activity')) - unix_timestamp(col('timestamp'))) / 86400)\n",
    "df_use = df_use.withColumn('time_diff', format_number(col('time_diff'), 0))\n",
    "df_use.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|                star| count|\n",
      "+--------------------+------+\n",
      "|2022-07-20 10:44:...|     1|\n",
      "|                   3| 10060|\n",
      "|2022-08-03 14:58:...|     1|\n",
      "|                null|160084|\n",
      "|                   5| 45910|\n",
      "|2023-01-24 01:23:...|     1|\n",
      "|2022-08-03 06:06:...|     1|\n",
      "|2022-08-30 20:17:...|     1|\n",
      "|2023-02-20 10:27:...|     1|\n",
      "|                   1| 13519|\n",
      "|           เสร็จสิ้น|    12|\n",
      "|2022-07-05 11:38:...|     1|\n",
      "|                   4| 20335|\n",
      "|2022-07-05 11:40:...|     1|\n",
      "|2022-07-17 16:58:...|     1|\n",
      "|2022-06-29 07:25:...|     1|\n",
      "|2022-07-25 13:21:...|     1|\n",
      "|                   2|  4544|\n",
      "+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_use.groupBy(col('star')).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(ticket_id='2021-9LHDM6', type=[''], organization=None, comment='ไม่มีภาพ', photo='https://storage.googleapis.com/traffy_public_bucket/attachment/2021-09/ba04e344d8011ae51fdcf6db72de76780575d10c.jpg', photo_after=None, coords=['13.79386', '100.48661'], address='1867 จรัญสนิทวงศ์ แขวง บางพลัด เขตบางพลัด กรุงเทพมหานคร 10700 ประเทศไทย', subdistrict='บางพลัด', district='บางพลัด', province='กรุงเทพมหานคร', timestamp='2021-09-01 10:44:00', state=0, star=None, count_reopen=None, last_activity='2022-02-22 04:59:00', time_diff='174') \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def check_first_null(filtered_df):\n",
    "    # Check if the filtered DataFrame is empty\n",
    "    if filtered_df.count() == 0:\n",
    "        return f\"No null values in {filtered_df}.\"\n",
    "    else:\n",
    "        first_row = filtered_df.head()\n",
    "        return first_row\n",
    "    \n",
    "star_null_df = df_use.filter(df_use.star.isNull())\n",
    "print(check_first_null(star_null_df), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                star|count|\n",
      "+--------------------+-----+\n",
      "|2022-07-20 10:44:...|    1|\n",
      "|2022-08-03 14:58:...|    1|\n",
      "|2023-01-24 01:23:...|    1|\n",
      "|2022-08-03 06:06:...|    1|\n",
      "|2022-08-30 20:17:...|    1|\n",
      "|2023-02-20 10:27:...|    1|\n",
      "|           เสร็จสิ้น|   12|\n",
      "|2022-07-05 11:38:...|    1|\n",
      "|2022-07-05 11:40:...|    1|\n",
      "|2022-07-17 16:58:...|    1|\n",
      "|2022-06-29 07:25:...|    1|\n",
      "|2022-07-25 13:21:...|    1|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_use.filter(length('star') > 1).groupBy(col('star')).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------+---------+--------------------+-------------------+-----+----+------------+-------------------+---------+\n",
      "|  ticket_id|       type|        organization|             comment|               photo|         photo_after|              coords|             address|   subdistrict| district|            province|          timestamp|state|star|count_reopen|      last_activity|time_diff|\n",
      "+-----------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------+---------+--------------------+-------------------+-----+----+------------+-------------------+---------+\n",
      "|2021-FYJTFP|  ความสะอาด|          เขตบางซื่อ|             ขยะเยอะ|https://storage.g...|                null|[13.81865, 100.53...|12/14 ถนน กรุงเทพ...|          null|     null|       กรุงเทพมหานคร|2021-09-03 12:51:00|    1|null|        null|2022-06-04 15:34:00|      274|\n",
      "|2021-8GKAR9|      สายไฟ|ยังไม่มีหน่วยงานร...|1. เถาวัลย์งอดบนส...|https://storage.g...|                null|[13.79704, 100.57...|335/31 ลาดพร้าว แ...|     สามเสนนอก| ห้วยขวาง|จังหวัดกรุงเทพมหานคร|2021-09-19 06:47:00|    0|null|        null|2022-02-22 04:30:00|      156|\n",
      "|2021-AFPUXZ|        ถนน|                null|1 ซ่อมทางเท้าหลัง...|https://storage.g...|                null|[13.72338, 100.52...|37 10 ซอย สีลม 9 ...|          สีลม|   บางรัก|       กรุงเทพมหานคร|2021-09-19 07:40:00|    0|null|        null|2022-02-22 04:30:00|      156|\n",
      "|2021-AFPUXZ|      สะพาน|                null|1 ซ่อมทางเท้าหลัง...|https://storage.g...|                null|[13.72338, 100.52...|37 10 ซอย สีลม 9 ...|          สีลม|   บางรัก|       กรุงเทพมหานคร|2021-09-19 07:40:00|    0|null|        null|2022-02-22 04:30:00|      156|\n",
      "|2021-CGPMUN|    น้ำท่วม|เขตประเวศ,ฝ่ายโยธ...|น้ำท่วมเวลาฝนตกแล...|https://storage.g...|https://storage.g...|[13.67891, 100.66...|189 เฉลิมพระเกียร...|       หนองบอน|   ประเวศ|       กรุงเทพมหานคร|2021-09-19 14:56:00|    1|   4|        null|2022-06-21 08:21:00|      275|\n",
      "|2021-CGPMUN|  ร้องเรียน|เขตประเวศ,ฝ่ายโยธ...|น้ำท่วมเวลาฝนตกแล...|https://storage.g...|https://storage.g...|[13.67891, 100.66...|189 เฉลิมพระเกียร...|       หนองบอน|   ประเวศ|       กรุงเทพมหานคร|2021-09-19 14:56:00|    1|   4|        null|2022-06-21 08:21:00|      275|\n",
      "|2021-8Z8JQ3|        ถนน|                null|1) พื้นที่นี้ขาดห...|https://storage.g...|                null|[13.72804, 100.86...|3/8 ขุมทอง-ลำต้อย...|        ขุมทอง|ลาดกระบัง|       กรุงเทพมหานคร|2021-09-20 00:24:00|    0|null|        null|2022-02-22 04:29:00|      155|\n",
      "|2021-8Z8JQ3|  ร้องเรียน|                null|1) พื้นที่นี้ขาดห...|https://storage.g...|                null|[13.72804, 100.86...|3/8 ขุมทอง-ลำต้อย...|        ขุมทอง|ลาดกระบัง|       กรุงเทพมหานคร|2021-09-20 00:24:00|    0|null|        null|2022-02-22 04:29:00|      155|\n",
      "|2021-8Z8JQ3|    น้ำท่วม|                null|1) พื้นที่นี้ขาดห...|https://storage.g...|                null|[13.72804, 100.86...|3/8 ขุมทอง-ลำต้อย...|        ขุมทอง|ลาดกระบัง|       กรุงเทพมหานคร|2021-09-20 00:24:00|    0|null|        null|2022-02-22 04:29:00|      155|\n",
      "|2021-8Z8JQ3|ความปลอดภัย|                null|1) พื้นที่นี้ขาดห...|https://storage.g...|                null|[13.72804, 100.86...|3/8 ขุมทอง-ลำต้อย...|        ขุมทอง|ลาดกระบัง|       กรุงเทพมหานคร|2021-09-20 00:24:00|    0|null|        null|2022-02-22 04:29:00|      155|\n",
      "|2021-G4FN8W|       คลอง|                null|   น้ำเน่าเสียในคลอง|https://storage.g...|                null|[13.74227, 100.62...|50 พระราม ที่ 9 แ...|       สวนหลวง|  สวนหลวง|       กรุงเทพมหานคร|2021-09-21 05:22:00|    0|null|        null|2022-02-22 04:29:00|      154|\n",
      "|2021-AFJYNF|        ถนน|                null|น้ำท่วม เอ่อล้นถน...|https://storage.g...|                null|[13.73614, 100.71...|3 ถนน พัฒนาชนบท 3...|คลองสองต้นนุ่น|ลาดกระบัง|       กรุงเทพมหานคร|2021-09-22 05:06:00|    0|null|        null|2022-02-22 04:29:00|      153|\n",
      "|2021-AFJYNF|    น้ำท่วม|                null|น้ำท่วม เอ่อล้นถน...|https://storage.g...|                null|[13.73614, 100.71...|3 ถนน พัฒนาชนบท 3...|คลองสองต้นนุ่น|ลาดกระบัง|       กรุงเทพมหานคร|2021-09-22 05:06:00|    0|null|        null|2022-02-22 04:29:00|      153|\n",
      "|2021-HAJULK|  ร้องเรียน|                null|มีการยกถนนในซอยเม...|https://storage.g...|                null|[13.79225, 100.71...|95 ซอย 12 มีนบุรี...|       มีนบุรี|  มีนบุรี|       กรุงเทพมหานคร|2021-09-23 06:25:00|    0|null|        null|2022-02-22 04:29:00|      152|\n",
      "|2021-HAJULK|        ถนน|                null|มีการยกถนนในซอยเม...|https://storage.g...|                null|[13.79225, 100.71...|95 ซอย 12 มีนบุรี...|       มีนบุรี|  มีนบุรี|       กรุงเทพมหานคร|2021-09-23 06:25:00|    0|null|        null|2022-02-22 04:29:00|      152|\n",
      "|2021-HAJULK|    น้ำท่วม|                null|มีการยกถนนในซอยเม...|https://storage.g...|                null|[13.79225, 100.71...|95 ซอย 12 มีนบุรี...|       มีนบุรี|  มีนบุรี|       กรุงเทพมหานคร|2021-09-23 06:25:00|    0|null|        null|2022-02-22 04:29:00|      152|\n",
      "|2021-7XATFA|      สะพาน|             เขตสาทร|สะพานลอยปรับปรุงไ...|https://storage.g...|                null|[13.72060, 100.52...|191/1 ถนน สาทรเหน...|       ยานนาวา|     สาทร|       กรุงเทพมหานคร|2021-09-26 05:03:00|    1|null|        null|2022-06-06 01:17:00|      253|\n",
      "|2021-79YL3M|        ถนน|                null|1.ซอยราษฎร์นิมิตร...|https://storage.g...|                null|[13.91732, 100.73...|147 ซอย ราษฎร์นิม...| สามวาตะวันออก|คลองสามวา|       กรุงเทพมหานคร|2021-09-28 23:01:00|    0|null|        null|2022-02-22 04:29:00|      146|\n",
      "|2021-9U2NJT|    น้ำท่วม|เขตบางซื่อ,ฝ่ายโย...|             น้ำท่วม|https://storage.g...|https://storage.g...|[13.81853, 100.53...|12/14 ถนน กรุงเทพ...|          null|     null|       กรุงเทพมหานคร|2021-10-14 10:45:00|    1|null|        null|2022-09-08 08:35:00|      329|\n",
      "|2021-F7A2PK|ท่อระบายน้ำ|                null|มีฝาท่อระบายน้ำชำ...|https://storage.g...|                null|[13.71937, 100.44...|19/31 ซอย เพชรเกษ...|       บางหว้า|ภาษีเจริญ|       กรุงเทพมหานคร|2021-11-12 02:19:00|    0|null|        null|2022-02-22 04:29:00|      102|\n",
      "+-----------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------+---------+--------------------+-------------------+-----+----+------------+-------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "first_element = udf(lambda x: x[0], StringType())\n",
    "# df_exploded = df_use.withColumn('type', first_element(df_use['type']))\n",
    "df_exploded = df_use.withColumn('type', explode(df_use['type']))\n",
    "df_exploded = df_exploded.filter(\"type != ''\")\n",
    "\n",
    "df_exploded.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t = df_exploded.withColumn(\"latitude\", col(\"coords\")[0]) \\\n",
    "       .withColumn(\"longitude\", col(\"coords\")[1]) \\\n",
    "       .drop(\"coords\")\n",
    "df_t = df_t.withColumn(\"latitude\", col(\"latitude\").cast('double'))\n",
    "df_t = df_t.withColumn(\"longitude\", col(\"longitude\").cast('double'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(ticket_id='จักขอบคุณอย่างยิ่ง\"', type='https://storage.googleapis.com/traffy_public_bucket/attachment/2022-02/5d20ecb864e916af948b4090ce9405be6f0b2f04.jpg', organization=None, comment='100.46930,13.75503', photo='1186 ถ. พรานนก แขวง บ้านช่างหล่อ เขตบางกอกน้อย กรุงเทพมหานคร 10700 ประเทศไทย', photo_after='บางขุนศรี', address='กรุงเทพมหานคร', subdistrict='2022-02-06 16:59:19.251528+00', district='กำลังดำเนินการ', province=None, timestamp=None, state=0, star=None, count_reopen=None, last_activity=None, time_diff=None, latitude=None, longitude=None) \n",
      "\n",
      "Row(ticket_id='จักขอบคุณอย่างยิ่ง\"', type='https://storage.googleapis.com/traffy_public_bucket/attachment/2022-02/5d20ecb864e916af948b4090ce9405be6f0b2f04.jpg', organization=None, comment='100.46930,13.75503', photo='1186 ถ. พรานนก แขวง บ้านช่างหล่อ เขตบางกอกน้อย กรุงเทพมหานคร 10700 ประเทศไทย', photo_after='บางขุนศรี', address='กรุงเทพมหานคร', subdistrict='2022-02-06 16:59:19.251528+00', district='กำลังดำเนินการ', province=None, timestamp=None, state=0, star=None, count_reopen=None, last_activity=None, time_diff=None, latitude=None, longitude=None) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "null_latitude = df_t.filter(df_t.latitude.isNull())\n",
    "null_longitude = df_t.filter(df_t.longitude.isNull())\n",
    "print(check_first_null(null_latitude), \"\\n\")\n",
    "print(check_first_null(null_longitude), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = ['type', 'latitude', 'longitude', 'subdistrict', 'district', 'timestamp', 'last_activity', 'organization', 'star', 'time_diff']\n",
    "for e in drop_list:\n",
    "    df_t = df_t.dropna(how='all', subset=[e])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest(df, label_col, numeric_col,  quantitative_col):\n",
    "    stages = []\n",
    "\n",
    "    # For label\n",
    "    label_indexer = StringIndexer(inputCol=label_col, outputCol='label')\n",
    "    indexer_model = label_indexer.fit(df)\n",
    "    df = indexer_model.transform(df)\n",
    "\n",
    "    # For features\n",
    "    for column_name in quantitative_col:\n",
    "        stringIndexer = StringIndexer(inputCol=column_name, outputCol=column_name+ \"_index\")\n",
    "        stages.append(stringIndexer)\n",
    "        oneHotEncoder = OneHotEncoder(inputCol=column_name+ \"_index\", outputCol=column_name + \"_onehot\")\n",
    "        stages.append(oneHotEncoder)\n",
    "\n",
    "    quantitative_cols = [s + \"_onehot\" for s in quantitative_col]\n",
    "    assembler = VectorAssembler(inputCols=numeric_col + quantitative_cols, outputCol='features')\n",
    "    stages.append(assembler)\n",
    "\n",
    "    pipeline = Pipeline(stages=stages)\n",
    "    preprocessed_data = pipeline.fit(df).transform(df)\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    train_data, test_data = preprocessed_data.randomSplit([0.7, 0.3], seed=123)\n",
    "\n",
    "    # Train Decision Tree classifier\n",
    "    dt = RandomForestClassifier(labelCol='label', featuresCol='features', maxDepth=6)\n",
    "    dt_model = dt.fit(train_data)\n",
    "    \n",
    "    # Make predictions on test set\n",
    "    predictions = dt_model.transform(test_data)\n",
    "    label_reverse = IndexToString(inputCol=\"prediction\", outputCol=\"predicted_result\", labels=indexer_model.labels)\n",
    "    predictions_res = label_reverse.transform(predictions)\n",
    "\n",
    "    # Evaluate performance\n",
    "    evaluator = MulticlassClassificationEvaluator(predictionCol='prediction', labelCol='label', metricName='accuracy')\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "    print('Accuracy:', accuracy)\n",
    "\n",
    "    return predictions_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4845711115733999\n"
     ]
    }
   ],
   "source": [
    "numeric_col = []\n",
    "quantitative_col = ['type', 'organization', 'star', 'time_diff']\n",
    "df_select = df_t.select(numeric_col + quantitative_col)\n",
    "try:\n",
    "    predictions_res = train_random_forest(df_select, 'star', numeric_col,  quantitative_col)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+\n",
      "|predicted_result|count|\n",
      "+----------------+-----+\n",
      "|               5|28756|\n",
      "|               4|   86|\n",
      "+----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_res.groupBy(col('predicted_result')).count().show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_linear_regression(df, label_col, numeric_col,  quantitative_col):\n",
    "    stages = []\n",
    "    df_select = df.select(numeric_col + quantitative_col)\n",
    "\n",
    "    # For label\n",
    "    label_indexer = StringIndexer(inputCol=label_col, outputCol='label')\n",
    "    indexer_model = label_indexer.fit(df_select)\n",
    "    df_select = indexer_model.transform(df_select)\n",
    "\n",
    "    # For features\n",
    "    for column_name in quantitative_col:\n",
    "        stringIndexer = StringIndexer(inputCol=column_name, outputCol=column_name+ \"_index\")\n",
    "        stages.append(stringIndexer)\n",
    "        oneHotEncoder = OneHotEncoder(inputCol=column_name+ \"_index\", outputCol=column_name + \"_onehot\")\n",
    "        stages.append(oneHotEncoder)\n",
    "\n",
    "    quantitative_cols = [s + \"_onehot\" for s in quantitative_col]\n",
    "    assembler = VectorAssembler(inputCols=numeric_col + quantitative_cols, outputCol='features')\n",
    "    stages.append(assembler)\n",
    "\n",
    "    pipeline = Pipeline(stages=stages)\n",
    "    preprocessed_data = pipeline.fit(df_select).transform(df_select)\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    train_data, test_data = preprocessed_data.randomSplit([0.7, 0.3], seed=123)\n",
    "\n",
    "    # Train Decision Tree classifier\n",
    "    poisson = GeneralizedLinearRegression(family='poisson', link='log', maxIter=10, regParam=0.3)\n",
    "    dt_model = poisson.fit(train_data, label_col)\n",
    "    predictions = dt_model.transform(test_data)\n",
    "\n",
    "    # Make predictions on test set\n",
    "    label_reverse = IndexToString(inputCol=\"prediction\", outputCol=\"predicted_result\", labels=indexer_model.labels)\n",
    "    predictions_res = label_reverse.transform(predictions)\n",
    "\n",
    "    # Evaluate the performance of the model using mean squared error\n",
    "    from pyspark.ml.evaluation import RegressionEvaluator\n",
    "    evaluator = RegressionEvaluator(predictionCol='prediction', labelCol=label_col, metricName='mse')\n",
    "    mse = evaluator.evaluate(predictions)\n",
    "    print('Mean Squared Error:', mse)\n",
    "\n",
    "    return predictions_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|timestamp          |\n",
      "+-------------------+\n",
      "|2021-09-19 14:56:00|\n",
      "|2021-09-19 14:56:00|\n",
      "|2021-12-09 12:29:00|\n",
      "|2021-12-09 12:29:00|\n",
      "|2021-12-18 14:50:00|\n",
      "|2021-12-22 10:15:00|\n",
      "|2021-12-28 03:59:00|\n",
      "|2022-01-28 04:09:00|\n",
      "|2022-02-01 18:11:00|\n",
      "|2022-02-04 12:06:00|\n",
      "|2022-02-06 06:23:00|\n",
      "|2022-02-15 02:47:00|\n",
      "|2022-02-16 15:45:00|\n",
      "|2022-02-16 15:45:00|\n",
      "|2022-02-26 09:20:00|\n",
      "|2022-02-26 14:36:00|\n",
      "|2022-05-18 05:25:00|\n",
      "|2022-05-22 17:47:00|\n",
      "|2022-05-24 11:21:00|\n",
      "|2022-05-25 04:02:00|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_t.select('timestamp').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23396\\2218380179.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Python 3.10.9)",
   "language": "python",
   "name": "py3109"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
